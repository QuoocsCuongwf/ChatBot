{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fb4263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/NCKH/DataPhuc/144-ndcp.signed_bá»™ xÃ¢y dá»±ng.pdf\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "\n",
    "Tk().withdraw()\n",
    "pdf_path = filedialog.askopenfilename(\n",
    "    filetypes=[(\"PDF files\", \"*.pdf\")]\n",
    ")\n",
    "\n",
    "print(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53b7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec75bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def is_text_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[0]\n",
    "        text = page.extract_text()\n",
    "        return text is not None and len(text.strip()) > 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d33384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_pdf(pdf_path):\n",
    "    full_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "    return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba8fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (0.11.8)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20251107 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pdfplumber) (20251107)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pdfplumber) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (44.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pdfplumber pdf2image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82eae8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b51edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c bin cá»§a Poppler\n",
    "# Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n nÃ y sau khi báº¡n táº£i vÃ  giáº£i nÃ©n Poppler\n",
    "poppler_path = r\"D:\\Release-25.12.0-0\\poppler-25.12.0\\Library\\bin\"  # Äiá»u chá»‰nh theo Ä‘Æ°á»ng dáº«n thá»±c táº¿\n",
    "\n",
    "images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "images[0].save(\"page_1.png\", \"PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbb22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t thÆ° viá»‡n OCR\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pytesseract pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b480a",
   "metadata": {},
   "source": [
    "### LÆ°u Ã½: CÃ i Ä‘áº·t Tesseract OCR\n",
    "Táº£i Tesseract OCR cho Windows tá»«: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "- Sau khi cÃ i Ä‘áº·t, thÃªm Ä‘Æ°á»ng dáº«n vÃ o PATH hoáº·c chá»‰ Ä‘á»‹nh trá»±c tiáº¿p trong code\n",
    "- VÃ­ dá»¥: `C:\\Program Files\\Tesseract-OCR\\tesseract.exe`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890dcdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n Tesseract (náº¿u chÆ°a cÃ³ trong PATH)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def ocr_from_image(image_path):\n",
    "    \"\"\"TrÃ­ch xuáº¥t text tá»« áº£nh báº±ng OCR\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    # Sá»­ dá»¥ng tiáº¿ng Viá»‡t: Ä‘áº£m báº£o Ä‘Ã£ cÃ i 'vie.traineddata'\n",
    "    text = pytesseract.image_to_string(img, lang='vie')\n",
    "    return text\n",
    "\n",
    "def ocr_from_pdf_images(images):\n",
    "    \"\"\"TrÃ­ch xuáº¥t text tá»« danh sÃ¡ch áº£nh (Ä‘Ã£ convert tá»« PDF)\"\"\"\n",
    "    full_text = \"\"\n",
    "    total = len(images)\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        # Chá»‰ hiá»ƒn thá»‹ progress má»—i 5 trang Ä‘á»ƒ giáº£m output\n",
    "        if i == 0 or (i+1) % 5 == 0 or (i+1) == total:\n",
    "            print(f\"   ðŸ”„ Äang xá»­ lÃ½: {i+1}/{total} trang...\", end='\\r')\n",
    "        \n",
    "        try:\n",
    "            text = pytesseract.image_to_string(img, lang='vie')\n",
    "            full_text += text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"\\n   âš ï¸ Lá»—i trang {i+1}: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n   âœ“ HoÃ n thÃ nh OCR: {total} trang\")\n",
    "    return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea553ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Chuáº©n hÃ³a vÄƒn báº£n: loáº¡i bá» khoáº£ng tráº¯ng thá»«a, xuá»‘ng dÃ²ng thá»«a\"\"\"\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d269eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_legal_document(text):\n",
    "    \"\"\"\n",
    "    PhÃ¢n tÃ­ch vÄƒn báº£n phÃ¡p luáº­t, giá»¯ nguyÃªn cáº¥u trÃºc Äiá»u, Khoáº£n, Äiá»ƒm\n",
    "    KhÃ´ng diá»…n giáº£i, khÃ´ng rÃºt gá»n\n",
    "    \"\"\"\n",
    "    # Khá»Ÿi táº¡o cáº¥u trÃºc\n",
    "    document = {\n",
    "        \"dieu\": []\n",
    "    }\n",
    "    \n",
    "    # TÃ¡ch cÃ¡c dÃ²ng\n",
    "    lines = text.split('\\n')\n",
    "    current_dieu = None\n",
    "    current_khoan = None\n",
    "    current_diem = None\n",
    "    buffer = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Nháº­n diá»‡n Äiá»u (Äiá»u X, Äiá»u X., ÄIá»€U X, etc.)\n",
    "        dieu_match = re.match(r'^(Äiá»u|ÄIá»€U)\\s+(\\d+[\\w]*)[\\.:]?\\s*(.*)', line, re.IGNORECASE)\n",
    "        if dieu_match:\n",
    "            # LÆ°u dá»¯ liá»‡u cÅ©\n",
    "            if current_diem and buffer:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            elif current_khoan and buffer:\n",
    "                current_khoan[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            elif current_dieu and buffer:\n",
    "                current_dieu[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            \n",
    "            # Táº¡o Äiá»u má»›i\n",
    "            current_dieu = {\n",
    "                \"so_dieu\": dieu_match.group(2),\n",
    "                \"tieu_de\": dieu_match.group(3).strip() if dieu_match.group(3) else \"\",\n",
    "                \"noi_dung\": \"\",\n",
    "                \"khoan\": []\n",
    "            }\n",
    "            document[\"dieu\"].append(current_dieu)\n",
    "            current_khoan = None\n",
    "            current_diem = None\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Khoáº£n (1. , 2. , etc. á»Ÿ Ä‘áº§u dÃ²ng)\n",
    "        khoan_match = re.match(r'^(\\d+)\\.\\s+(.*)', line)\n",
    "        if khoan_match and current_dieu:\n",
    "            # LÆ°u dá»¯ liá»‡u cÅ©\n",
    "            if current_diem and buffer:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            elif current_khoan and buffer:\n",
    "                current_khoan[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            \n",
    "            # Táº¡o Khoáº£n má»›i\n",
    "            current_khoan = {\n",
    "                \"so_khoan\": khoan_match.group(1),\n",
    "                \"noi_dung\": khoan_match.group(2).strip(),\n",
    "                \"diem\": []\n",
    "            }\n",
    "            current_dieu[\"khoan\"].append(current_khoan)\n",
    "            current_diem = None\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Äiá»ƒm (a), b), c), etc.)\n",
    "        diem_match = re.match(r'^([a-z]|[Ä‘])\\)\\s+(.*)', line, re.IGNORECASE)\n",
    "        if diem_match and current_khoan:\n",
    "            # LÆ°u dá»¯ liá»‡u cÅ©\n",
    "            if current_diem and buffer:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(buffer).strip()\n",
    "                buffer = []\n",
    "            \n",
    "            # Táº¡o Äiá»ƒm má»›i\n",
    "            current_diem = {\n",
    "                \"so_diem\": diem_match.group(1),\n",
    "                \"noi_dung\": diem_match.group(2).strip()\n",
    "            }\n",
    "            current_khoan[\"diem\"].append(current_diem)\n",
    "            continue\n",
    "        \n",
    "        # Ná»™i dung tiáº¿p theo (thÃªm vÃ o buffer)\n",
    "        buffer.append(line)\n",
    "    \n",
    "    # LÆ°u pháº§n cuá»‘i\n",
    "    if current_diem and buffer:\n",
    "        current_diem[\"noi_dung\"] += ' ' + ' '.join(buffer).strip()\n",
    "    elif current_khoan and buffer:\n",
    "        current_khoan[\"noi_dung\"] += ' ' + ' '.join(buffer).strip()\n",
    "    elif current_dieu and buffer:\n",
    "        current_dieu[\"noi_dung\"] += ' ' + ' '.join(buffer).strip()\n",
    "    \n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942b572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WORKFLOW CHÃNH: Xá»­ lÃ½ PDF phÃ¡p luáº­t\n",
    "# import os\n",
    "\n",
    "# print(\"=== Há»† THá»NG TRÃCH XUáº¤T VÄ‚N Báº¢N PHÃP LUáº¬T ===\\n\")\n",
    "\n",
    "# # BÆ°á»›c 1: Sá»­ dá»¥ng pdfplumber Ä‘á»ƒ phÃ¢n loáº¡i PDF\n",
    "# print(\"Äang phÃ¢n tÃ­ch loáº¡i PDF...\")\n",
    "# is_text = is_text_pdf(pdf_path)\n",
    "# print(f\"Káº¿t quáº£: {'PDF dáº¡ng TEXT (cÃ³ thá»ƒ trÃ­ch xuáº¥t trá»±c tiáº¿p)' if is_text else 'PDF dáº¡ng SCAN (cáº§n OCR)'}\\n\")\n",
    "\n",
    "# # BÆ°á»›c 2: TrÃ­ch xuáº¥t vÄƒn báº£n theo loáº¡i PDF\n",
    "# if is_text:\n",
    "#     print(\"Äang trÃ­ch xuáº¥t text tá»« PDF báº±ng pdfplumber...\")\n",
    "#     raw_text = extract_text_pdf(pdf_path)\n",
    "# else:\n",
    "#     print(\"Äang chuyá»ƒn Ä‘á»•i PDF sang áº£nh...\")\n",
    "#     images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "#     print(f\"âœ“ ÄÃ£ chuyá»ƒn Ä‘á»•i {len(images)} trang\\n\")\n",
    "    \n",
    "#     print(\"Äang thá»±c hiá»‡n OCR vá»›i Tesseract...\")\n",
    "#     raw_text = ocr_from_pdf_images(images)\n",
    "\n",
    "# print(f\"âœ“ ÄÃ£ trÃ­ch xuáº¥t {len(raw_text)} kÃ½ tá»±\\n\")\n",
    "\n",
    "# # BÆ°á»›c 3: Chuáº©n hÃ³a vÄƒn báº£n\n",
    "# print(\"Äang chuáº©n hÃ³a vÄƒn báº£n...\")\n",
    "# raw_text = normalize_text(raw_text)\n",
    "# print(f\"âœ“ Sau chuáº©n hÃ³a: {len(raw_text)} kÃ½ tá»±\\n\")\n",
    "\n",
    "# # BÆ°á»›c 4: PhÃ¢n tÃ­ch cáº¥u trÃºc vÄƒn báº£n phÃ¡p luáº­t\n",
    "# print(\"Äang phÃ¢n tÃ­ch cáº¥u trÃºc Äiá»u, Khoáº£n, Äiá»ƒm...\")\n",
    "# parsed_data = parse_legal_document(raw_text)\n",
    "\n",
    "# # BÆ°á»›c 5: Chuyá»ƒn Ä‘á»•i sang JSON\n",
    "# json_output = json.dumps(parsed_data, ensure_ascii=False, indent=2)\n",
    "\n",
    "# # BÆ°á»›c 6: LÆ°u káº¿t quáº£\n",
    "# output_path = os.path.splitext(pdf_path)[0] + \"_extracted.json\"\n",
    "# with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#     f.write(json_output)\n",
    "\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(f\"âœ“ HOÃ€N THÃ€NH!\")\n",
    "# print(f\"{'='*60}\")\n",
    "# print(f\"ðŸ“„ File JSON: {output_path}\")\n",
    "# print(f\"ðŸ“Š Sá»‘ Äiá»u: {len(parsed_data['dieu'])}\")\n",
    "# print(f\"ðŸ“ KÃ­ch thÆ°á»›c JSON: {len(json_output):,} kÃ½ tá»±\")\n",
    "# print(f\"{'='*60}\\n\")\n",
    "\n",
    "# # Hiá»ƒn thá»‹ preview káº¿t quáº£\n",
    "# print(\"=== PREVIEW Káº¾T QUáº¢ JSON (2000 kÃ½ tá»± Ä‘áº§u) ===\")\n",
    "# print(json_output[:2000] + \"...\" if len(json_output) > 2000 else json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e8876ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PhÃ¢n tÃ­ch cáº¥u trÃºc file PDF máº«u\n",
    "# import pdfplumber\n",
    "\n",
    "# sample_pdf = r\"d:\\NCKH\\DataPhuc\\120-cp.signed_qlyBTP.pdf\"\n",
    "\n",
    "# with pdfplumber.open(sample_pdf) as pdf:\n",
    "#     print(f\"Tá»•ng sá»‘ trang: {len(pdf.pages)}\\n\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(\"Ná»˜I DUNG 3 TRANG Äáº¦U TIÃŠN:\")\n",
    "#     print(\"=\"*70)\n",
    "    \n",
    "#     for i in range(min(3, len(pdf.pages))):\n",
    "#         page = pdf.pages[i]\n",
    "#         text = page.extract_text()\n",
    "#         print(f\"\\n{'='*70}\")\n",
    "#         print(f\"TRANG {i+1}\")\n",
    "#         print('='*70)\n",
    "#         print(text[:2000] if text and len(text) > 2000 else text or \"[KhÃ´ng trÃ­ch xuáº¥t Ä‘Æ°á»£c]\")\n",
    "#         if text and len(text) > 2000:\n",
    "#             print(\"\\n[...cÃ²n tiáº¿p...]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa39762",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Cáº¤U TRÃšC JSON Há»¢P LÃ CHO VÄ‚N Báº¢N PHÃP LUáº¬T VIá»†T NAM\n",
    "\n",
    "### PhÃ¢n tÃ­ch yÃªu cáº§u:\n",
    "1. **Giá»¯ nguyÃªn cáº¥u trÃºc**: Äiá»u, Khoáº£n, Äiá»ƒm\n",
    "2. **KhÃ´ng diá»…n giáº£i, khÃ´ng rÃºt gá»n**: LÆ°u toÃ n bá»™ ná»™i dung gá»‘c\n",
    "3. **Metadata Ä‘áº§y Ä‘á»§**: ThÃ´ng tin vÄƒn báº£n, cÆ¡ quan ban hÃ nh, ngÃ y thÃ¡ng\n",
    "\n",
    "### Cáº¥u trÃºc JSON Ä‘Æ°á»£c Ä‘á» xuáº¥t:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"metadata\": {\n",
    "    \"loai_van_ban\": \"Nghá»‹ Ä‘á»‹nh\",\n",
    "    \"so_hieu\": \"120/2025/NÄ-CP\",\n",
    "    \"trich_yeu\": \"Quy Ä‘á»‹nh vá»...\",\n",
    "    \"co_quan_ban_hanh\": \"ChÃ­nh phá»§\",\n",
    "    \"nguoi_ky\": \"Thá»§ tÆ°á»›ng ChÃ­nh phá»§\",\n",
    "    \"ngay_ban_hanh\": \"DD/MM/YYYY\",\n",
    "    \"ngay_hieu_luc\": \"DD/MM/YYYY\",\n",
    "    \"so_trang\": 14,\n",
    "    \"can_cu_phap_ly\": [\"Luáº­t...\", \"Nghá»‹ quyáº¿t...\"]\n",
    "  },\n",
    "  \"phan_mo_dau\": {\n",
    "    \"co_quan_ban_hanh\": \"...\",\n",
    "    \"ten_quoc_gia\": \"...\",\n",
    "    \"quoc_hieu\": \"...\",\n",
    "    \"so_hieu\": \"...\",\n",
    "    \"noi_ban_hanh\": \"...\",\n",
    "    \"ngay_thang_nam\": \"...\"\n",
    "  },\n",
    "  \"ten_van_ban\": \"NGHá»Š Äá»ŠNH...\",\n",
    "  \"can_cu_phap_ly\": [\n",
    "    \"CÄƒn cá»© Luáº­t...\",\n",
    "    \"CÄƒn cá»© Nghá»‹ quyáº¿t...\"\n",
    "  ],\n",
    "  \"theo_de_nghi\": \"Theo Ä‘á» nghá»‹ cá»§a Bá»™ trÆ°á»Ÿng Bá»™...\",\n",
    "  \"phan_quyet_dinh\": \"ChÃ­nh phá»§ ban hÃ nh Nghá»‹ Ä‘á»‹nh...\",\n",
    "  \"chuong\": [\n",
    "    {\n",
    "      \"so_chuong\": \"I\",\n",
    "      \"ten_chuong\": \"QUY Äá»ŠNH CHUNG\",\n",
    "      \"dieu\": [\n",
    "        {\n",
    "          \"so_dieu\": \"1\",\n",
    "          \"tieu_de\": \"Pháº¡m vi Ä‘iá»u chá»‰nh\",\n",
    "          \"noi_dung_tong_quat\": \"Ná»™i dung khÃ´ng thuá»™c khoáº£n nÃ o\",\n",
    "          \"khoan\": [\n",
    "            {\n",
    "              \"so_khoan\": \"1\",\n",
    "              \"noi_dung\": \"Ná»™i dung khoáº£n 1...\",\n",
    "              \"diem\": [\n",
    "                {\n",
    "                  \"so_diem\": \"a\",\n",
    "                  \"noi_dung\": \"Ná»™i dung Ä‘iá»ƒm a...\"\n",
    "                },\n",
    "                {\n",
    "                  \"so_diem\": \"b\",\n",
    "                  \"noi_dung\": \"Ná»™i dung Ä‘iá»ƒm b...\"\n",
    "                }\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"so_khoan\": \"2\",\n",
    "              \"noi_dung\": \"Ná»™i dung khoáº£n 2...\",\n",
    "              \"diem\": []\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"dieu_khoan_thi_hanh\": {\n",
    "    \"hieu_luc\": \"Nghá»‹ Ä‘á»‹nh nÃ y cÃ³ hiá»‡u lá»±c...\",\n",
    "    \"trach_nhiem_thi_hanh\": \"CÃ¡c Bá»™ trÆ°á»Ÿng, Thá»§ trÆ°á»Ÿng...\",\n",
    "    \"noi_nhan\": [\"...\", \"...\"]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Æ¯u Ä‘iá»ƒm cá»§a cáº¥u trÃºc nÃ y:\n",
    "\n",
    "âœ… **Äáº§y Ä‘á»§ metadata**: Sá»‘ hiá»‡u, ngÃ y ban hÃ nh, cÆ¡ quan...  \n",
    "âœ… **PhÃ¢n cáº¥p rÃµ rÃ ng**: ChÆ°Æ¡ng â†’ Äiá»u â†’ Khoáº£n â†’ Äiá»ƒm  \n",
    "âœ… **Giá»¯ nguyÃªn ná»™i dung**: KhÃ´ng diá»…n giáº£i hay rÃºt gá»n  \n",
    "âœ… **Dá»… truy váº¥n**: CÃ³ thá»ƒ tÃ¬m kiáº¿m theo Äiá»u, Khoáº£n, Äiá»ƒm  \n",
    "âœ… **Má»Ÿ rá»™ng Ä‘Æ°á»£c**: CÃ³ thá»ƒ thÃªm trÆ°á»ng má»›i náº¿u cáº§n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e30e06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_legal_document_v2(text):\n",
    "    \"\"\"\n",
    "    PhÃ¢n tÃ­ch vÄƒn báº£n phÃ¡p luáº­t vá»›i cáº¥u trÃºc JSON Ä‘áº§y Ä‘á»§\n",
    "    Bao gá»“m: Metadata, ChÆ°Æ¡ng, Äiá»u, Khoáº£n, Äiá»ƒm\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    document = {\n",
    "        \"metadata\": {\n",
    "            \"loai_van_ban\": \"\",\n",
    "            \"so_hieu\": \"\",\n",
    "            \"trich_yeu\": \"\",\n",
    "            \"co_quan_ban_hanh\": \"\",\n",
    "            \"nguoi_ky\": \"\",\n",
    "            \"ngay_ban_hanh\": \"\",\n",
    "            \"ngay_hieu_luc\": \"\",\n",
    "            \"so_trang\": 0\n",
    "        },\n",
    "        \"phan_mo_dau\": {\n",
    "            \"co_quan_ban_hanh\": \"\",\n",
    "            \"ten_quoc_gia\": \"\",\n",
    "            \"quoc_hieu\": \"\",\n",
    "            \"so_hieu\": \"\",\n",
    "            \"noi_ban_hanh\": \"\",\n",
    "            \"ngay_thang_nam\": \"\"\n",
    "        },\n",
    "        \"ten_van_ban\": \"\",\n",
    "        \"can_cu_phap_ly\": [],\n",
    "        \"theo_de_nghi\": \"\",\n",
    "        \"phan_quyet_dinh\": \"\",\n",
    "        \"chuong\": []\n",
    "    }\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # TrÃ­ch xuáº¥t metadata tá»« Ä‘áº§u vÄƒn báº£n\n",
    "    for i, line in enumerate(lines[:50]):  # Chá»‰ xem 50 dÃ²ng Ä‘áº§u\n",
    "        line = line.strip()\n",
    "        \n",
    "        # TÃ¬m sá»‘ hiá»‡u\n",
    "        if re.search(r'Sá»‘:\\s*(\\d+[/\\d\\w\\-]+)', line, re.IGNORECASE):\n",
    "            match = re.search(r'Sá»‘:\\s*(\\d+[/\\d\\w\\-]+)', line, re.IGNORECASE)\n",
    "            document[\"metadata\"][\"so_hieu\"] = match.group(1)\n",
    "            document[\"phan_mo_dau\"][\"so_hieu\"] = match.group(1)\n",
    "        \n",
    "        # TÃ¬m loáº¡i vÄƒn báº£n\n",
    "        if re.search(r'(NGHá»Š Äá»ŠNH|QUYáº¾T Äá»ŠNH|THÃ”NG TÆ¯|LUáº¬T|PHÃP Lá»†NH)', line, re.IGNORECASE):\n",
    "            match = re.search(r'(NGHá»Š Äá»ŠNH|QUYáº¾T Äá»ŠNH|THÃ”NG TÆ¯|LUáº¬T|PHÃP Lá»†NH)', line, re.IGNORECASE)\n",
    "            document[\"metadata\"][\"loai_van_ban\"] = match.group(1)\n",
    "        \n",
    "        # TÃ¬m ngÃ y ban hÃ nh\n",
    "        if re.search(r'ngÃ y\\s+(\\d{1,2})\\s+thÃ¡ng\\s+(\\d{1,2})\\s+nÄƒm\\s+(\\d{4})', line, re.IGNORECASE):\n",
    "            match = re.search(r'ngÃ y\\s+(\\d{1,2})\\s+thÃ¡ng\\s+(\\d{1,2})\\s+nÄƒm\\s+(\\d{4})', line, re.IGNORECASE)\n",
    "            document[\"metadata\"][\"ngay_ban_hanh\"] = f\"{match.group(1)}/{match.group(2)}/{match.group(3)}\"\n",
    "            document[\"phan_mo_dau\"][\"ngay_thang_nam\"] = line\n",
    "        \n",
    "        # TÃ¬m cÆ¡ quan ban hÃ nh\n",
    "        if \"CÆ¡ quan phÃ¡t hÃ nh:\" in line or \"CHÃNH PHá»¦\" in line:\n",
    "            document[\"metadata\"][\"co_quan_ban_hanh\"] = line.replace(\"CÆ¡ quan phÃ¡t hÃ nh:\", \"\").strip()\n",
    "            document[\"phan_mo_dau\"][\"co_quan_ban_hanh\"] = line\n",
    "    \n",
    "    # PhÃ¢n tÃ­ch cáº¥u trÃºc ChÆ°Æ¡ng - Äiá»u - Khoáº£n - Äiá»ƒm\n",
    "    current_chuong = None\n",
    "    current_dieu = None\n",
    "    current_khoan = None\n",
    "    current_diem = None\n",
    "    buffer = []\n",
    "    can_cu_buffer = []\n",
    "    is_can_cu = False\n",
    "    is_collecting_chuong_name = False\n",
    "    chuong_name_buffer = []\n",
    "    is_collecting_dieu_title = False\n",
    "    dieu_title_buffer = []\n",
    "    is_collecting_khoan_content = False\n",
    "    khoan_content_buffer = []\n",
    "    is_collecting_diem_content = False\n",
    "    diem_content_buffer = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "        if not line_stripped:\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n CÄƒn cá»© phÃ¡p lÃ½\n",
    "        if re.match(r'^CÄƒn cá»©\\s+', line_stripped, re.IGNORECASE):\n",
    "            is_can_cu = True\n",
    "            can_cu_buffer.append(line_stripped)\n",
    "            continue\n",
    "        elif is_can_cu and line_stripped.endswith(';'):\n",
    "            can_cu_buffer.append(line_stripped)\n",
    "            document[\"can_cu_phap_ly\"].append(' '.join(can_cu_buffer))\n",
    "            can_cu_buffer = []\n",
    "            is_can_cu = False\n",
    "            continue\n",
    "        elif is_can_cu:\n",
    "            can_cu_buffer.append(line_stripped)\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n ChÆ°Æ¡ng\n",
    "        chuong_match = re.match(r'^(ChÆ°Æ¡ng|CHÆ¯Æ NG)\\s+([IVXLCDM]+|[\\dA-Z]+)[\\.:]?\\s*(.*)', line_stripped, re.IGNORECASE)\n",
    "        if chuong_match:\n",
    "            current_chuong = {\n",
    "                \"so_chuong\": chuong_match.group(2),\n",
    "                \"ten_chuong\": \"\",  # Sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau\n",
    "                \"dieu\": []\n",
    "            }\n",
    "            document[\"chuong\"].append(current_chuong)\n",
    "            current_dieu = None\n",
    "            current_khoan = None\n",
    "            current_diem = None\n",
    "            buffer = []\n",
    "            # Báº¯t Ä‘áº§u thu tháº­p tÃªn chÆ°Æ¡ng (cÃ³ thá»ƒ nhiá»u dÃ²ng)\n",
    "            is_collecting_chuong_name = True\n",
    "            chuong_name_buffer = []\n",
    "            if chuong_match.group(3).strip():\n",
    "                chuong_name_buffer.append(chuong_match.group(3).strip())\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Äiá»u CHÃNH (pháº£i cÃ³ dáº¥u cháº¥m hoáº·c hai cháº¥m SAU sá»‘, khÃ´ng pháº£i tham chiáº¿u)\n",
    "        # VÃ­ dá»¥: \"Äiá»u 4.\" hoáº·c \"Äiá»u 4:\" â†’ Äiá»u chÃ­nh\n",
    "        # Loáº¡i trá»«: \"Äiá»u 4 Nghá»‹ quyáº¿t\" â†’ tham chiáº¿u\n",
    "        dieu_match = re.match(r'^(Äiá»u|ÄIá»€U)\\s+(\\d+[\\w]*)[\\.:]\\s*(.*)', line_stripped, re.IGNORECASE)\n",
    "        if dieu_match:\n",
    "            # Kiá»ƒm tra cÃ³ pháº£i tham chiáº¿u vÄƒn báº£n khÃ¡c khÃ´ng\n",
    "            rest_text = dieu_match.group(3).strip()\n",
    "            # Náº¿u ngay sau \"Äiá»u X.\" cÃ³ tÃªn vÄƒn báº£n â†’ Ä‘Ã¢y lÃ  tham chiáº¿u, khÃ´ng pháº£i Äiá»u chÃ­nh\n",
    "            if re.match(r'^(Nghá»‹ quyáº¿t|Nghá»‹ Ä‘á»‹nh|Quyáº¿t Ä‘á»‹nh|ThÃ´ng tÆ°|Luáº­t|PhÃ¡p lá»‡nh|NÄ-CP|QH\\d+)', rest_text, re.IGNORECASE):\n",
    "                # ÄÃ¢y lÃ  tham chiáº¿u, khÃ´ng táº¡o Äiá»u má»›i, thÃªm vÃ o ná»™i dung hiá»‡n táº¡i\n",
    "                if is_collecting_dieu_title:\n",
    "                    dieu_title_buffer.append(line_stripped)\n",
    "                elif is_collecting_diem_content:\n",
    "                    diem_content_buffer.append(line_stripped)\n",
    "                elif is_collecting_khoan_content:\n",
    "                    khoan_content_buffer.append(line_stripped)\n",
    "                else:\n",
    "                    buffer.append(line_stripped)\n",
    "                continue\n",
    "            \n",
    "            # ÄÃ¢y lÃ  Äiá»u chÃ­nh, táº¡o Äiá»u má»›i\n",
    "            # HoÃ n thiá»‡n tÃªn chÆ°Æ¡ng náº¿u Ä‘ang thu tháº­p\n",
    "            if is_collecting_chuong_name and current_chuong:\n",
    "                current_chuong[\"ten_chuong\"] = ' '.join(chuong_name_buffer).strip()\n",
    "                is_collecting_chuong_name = False\n",
    "                chuong_name_buffer = []\n",
    "            \n",
    "            # HoÃ n thiá»‡n tiÃªu Ä‘á» Äiá»u cÅ©\n",
    "            if is_collecting_dieu_title and current_dieu:\n",
    "                current_dieu[\"tieu_de\"] = ' '.join(dieu_title_buffer).strip()\n",
    "                is_collecting_dieu_title = False\n",
    "                dieu_title_buffer = []\n",
    "            \n",
    "            # HoÃ n thiá»‡n ná»™i dung Äiá»ƒm cÅ©\n",
    "            if is_collecting_diem_content and current_diem:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(diem_content_buffer).strip()\n",
    "                is_collecting_diem_content = False\n",
    "                diem_content_buffer = []\n",
    "            # HoÃ n thiá»‡n ná»™i dung Khoáº£n cÅ©\n",
    "            elif is_collecting_khoan_content and current_khoan:\n",
    "                current_khoan[\"noi_dung\"] = ' '.join(khoan_content_buffer).strip()\n",
    "                is_collecting_khoan_content = False\n",
    "                khoan_content_buffer = []\n",
    "            \n",
    "            # Táº¡o Äiá»u má»›i\n",
    "            current_dieu = {\n",
    "                \"so_dieu\": dieu_match.group(2),\n",
    "                \"tieu_de\": \"\",\n",
    "                \"khoan\": []\n",
    "            }\n",
    "            \n",
    "            # ThÃªm vÃ o ChÆ°Æ¡ng hoáº·c root\n",
    "            if current_chuong:\n",
    "                current_chuong[\"dieu\"].append(current_dieu)\n",
    "            else:\n",
    "                # Náº¿u chÆ°a cÃ³ chÆ°Æ¡ng, táº¡o chÆ°Æ¡ng máº·c Ä‘á»‹nh\n",
    "                if not document[\"chuong\"]:\n",
    "                    document[\"chuong\"].append({\n",
    "                        \"so_chuong\": \"\",\n",
    "                        \"ten_chuong\": \"\",\n",
    "                        \"dieu\": []\n",
    "                    })\n",
    "                    current_chuong = document[\"chuong\"][0]\n",
    "                current_chuong[\"dieu\"].append(current_dieu)\n",
    "            \n",
    "            current_khoan = None\n",
    "            current_diem = None\n",
    "            # Báº¯t Ä‘áº§u thu tháº­p tiÃªu Ä‘á» Äiá»u (nhiá»u dÃ²ng chá»¯ in Ä‘áº­m)\n",
    "            is_collecting_dieu_title = True\n",
    "            dieu_title_buffer = []\n",
    "            # ThÃªm pháº§n text cÃ¹ng dÃ²ng vá»›i sá»‘ Äiá»u (náº¿u cÃ³)\n",
    "            if dieu_match.group(3).strip():\n",
    "                dieu_title_buffer.append(dieu_match.group(3).strip())\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Khoáº£n (CHá»ˆ khi cÃ³ cáº£ sá»‘ VÃ€ ná»™i dung)\n",
    "        khoan_match = re.match(r'^(\\d+)\\.\\s+(.+)', line_stripped)\n",
    "        if khoan_match and current_dieu and len(khoan_match.group(2).strip()) > 0:\n",
    "            # HoÃ n thiá»‡n tiÃªu Ä‘á» Äiá»u náº¿u Ä‘ang thu tháº­p\n",
    "            if is_collecting_dieu_title:\n",
    "                current_dieu[\"tieu_de\"] = ' '.join(dieu_title_buffer).strip()\n",
    "                is_collecting_dieu_title = False\n",
    "                dieu_title_buffer = []\n",
    "            \n",
    "            # HoÃ n thiá»‡n ná»™i dung Äiá»ƒm cÅ©\n",
    "            if is_collecting_diem_content and current_diem:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(diem_content_buffer).strip()\n",
    "                is_collecting_diem_content = False\n",
    "                diem_content_buffer = []\n",
    "            # HoÃ n thiá»‡n ná»™i dung Khoáº£n cÅ©\n",
    "            elif is_collecting_khoan_content and current_khoan:\n",
    "                current_khoan[\"noi_dung\"] = ' '.join(khoan_content_buffer).strip()\n",
    "                is_collecting_khoan_content = False\n",
    "                khoan_content_buffer = []\n",
    "            \n",
    "            # Táº¡o Khoáº£n má»›i\n",
    "            current_khoan = {\n",
    "                \"so_khoan\": khoan_match.group(1),\n",
    "                \"noi_dung\": khoan_match.group(2).strip(),\n",
    "                \"diem\": []\n",
    "            }\n",
    "            current_dieu[\"khoan\"].append(current_khoan)\n",
    "            current_diem = None\n",
    "            # Báº¯t Ä‘áº§u thu tháº­p ná»™i dung Khoáº£n\n",
    "            is_collecting_khoan_content = True\n",
    "            khoan_content_buffer = [khoan_match.group(2).strip()]\n",
    "            continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Äiá»ƒm (bao gá»“m cáº£ \"1)\" - OCR nháº§m \"l)\" thÃ nh \"1)\")\n",
    "        diem_match = re.match(r'^([a-z]|Ä‘|1)\\)\\s+(.*)', line_stripped, re.IGNORECASE)\n",
    "        if diem_match and current_khoan:\n",
    "            # Náº¿u match \"1)\" nhÆ°ng chÆ°a cÃ³ Ä‘iá»ƒm nÃ o â†’ Ä‘Ã¢y lÃ  Khoáº£n 1, khÃ´ng pháº£i Äiá»ƒm\n",
    "            # Náº¿u match \"1)\" vÃ  Ä‘Ã£ cÃ³ Ä‘iá»ƒm â†’ Ä‘Ã¢y lÃ  Äiá»ƒm \"l\" bá»‹ OCR nháº§m\n",
    "            if diem_match.group(1) == \"1\" and len(current_khoan[\"diem\"]) == 0:\n",
    "                # ÄÃ¢y lÃ  Khoáº£n 1, khÃ´ng pháº£i Äiá»ƒm, bá» qua vÃ  xá»­ lÃ½ nhÆ° Khoáº£n bÃªn dÆ°á»›i\n",
    "                pass\n",
    "            else:\n",
    "                # ÄÃ¢y lÃ  Äiá»ƒm (hoáº·c \"l\" bá»‹ nháº§m thÃ nh \"1\")\n",
    "                # HoÃ n thiá»‡n ná»™i dung Äiá»ƒm cÅ©\n",
    "                if is_collecting_diem_content and current_diem:\n",
    "                    current_diem[\"noi_dung\"] = ' '.join(diem_content_buffer).strip()\n",
    "                    is_collecting_diem_content = False\n",
    "                    diem_content_buffer = []\n",
    "                # Dá»«ng thu tháº­p ná»™i dung Khoáº£n\n",
    "                elif is_collecting_khoan_content:\n",
    "                    is_collecting_khoan_content = False\n",
    "                    if khoan_content_buffer:\n",
    "                        current_khoan[\"noi_dung\"] = ' '.join(khoan_content_buffer).strip()\n",
    "                        khoan_content_buffer = []\n",
    "                \n",
    "                # Táº¡o Äiá»ƒm má»›i (náº¿u \"1\" thÃ¬ Ä‘á»•i thÃ nh \"l\")\n",
    "                so_diem = diem_match.group(1)\n",
    "                if so_diem == \"1\":\n",
    "                    so_diem = \"l\"  # OCR nháº§m, sá»­a láº¡i\n",
    "                \n",
    "                current_diem = {\n",
    "                    \"so_diem\": so_diem,\n",
    "                    \"noi_dung\": diem_match.group(2).strip()\n",
    "                }\n",
    "                current_khoan[\"diem\"].append(current_diem)\n",
    "                # Báº¯t Ä‘áº§u thu tháº­p ná»™i dung Äiá»ƒm\n",
    "                is_collecting_diem_content = True\n",
    "                diem_content_buffer = [diem_match.group(2).strip()]\n",
    "                continue\n",
    "        \n",
    "        # Nháº­n diá»‡n Khoáº£n (CHá»ˆ khi cÃ³ cáº£ sá»‘ VÃ€ ná»™i dung)\n",
    "        # Äáº·t sau Äiá»ƒm Ä‘á»ƒ Æ°u tiÃªn Äiá»ƒm trÆ°á»›c\n",
    "        khoan_match = re.match(r'^(\\d+)\\.\\s+(.+)', line_stripped)\n",
    "        if khoan_match and current_dieu and len(khoan_match.group(2).strip()) > 0:\n",
    "            # HoÃ n thiá»‡n tiÃªu Ä‘á» Äiá»u náº¿u Ä‘ang thu tháº­p\n",
    "            if is_collecting_dieu_title:\n",
    "                current_dieu[\"tieu_de\"] = ' '.join(dieu_title_buffer).strip()\n",
    "                is_collecting_dieu_title = False\n",
    "                dieu_title_buffer = []\n",
    "            \n",
    "            # HoÃ n thiá»‡n ná»™i dung Äiá»ƒm cÅ©\n",
    "            if is_collecting_diem_content and current_diem:\n",
    "                current_diem[\"noi_dung\"] = ' '.join(diem_content_buffer).strip()\n",
    "                is_collecting_diem_content = False\n",
    "                diem_content_buffer = []\n",
    "            # HoÃ n thiá»‡n ná»™i dung Khoáº£n cÅ©\n",
    "            elif is_collecting_khoan_content and current_khoan:\n",
    "                current_khoan[\"noi_dung\"] = ' '.join(khoan_content_buffer).strip()\n",
    "                is_collecting_khoan_content = False\n",
    "                khoan_content_buffer = []\n",
    "            \n",
    "            # Táº¡o Khoáº£n má»›i\n",
    "            current_khoan = {\n",
    "                \"so_khoan\": khoan_match.group(1),\n",
    "                \"noi_dung\": khoan_match.group(2).strip(),\n",
    "                \"diem\": []\n",
    "            }\n",
    "            current_dieu[\"khoan\"].append(current_khoan)\n",
    "            current_diem = None\n",
    "            # Báº¯t Ä‘áº§u thu tháº­p ná»™i dung Khoáº£n\n",
    "            is_collecting_khoan_content = True\n",
    "            khoan_content_buffer = [khoan_match.group(2).strip()]\n",
    "            continue\n",
    "        \n",
    "        # Thu tháº­p tÃªn chÆ°Æ¡ng nhiá»u dÃ²ng\n",
    "        if is_collecting_chuong_name:\n",
    "            chuong_name_buffer.append(line_stripped)\n",
    "            continue\n",
    "        \n",
    "        # Thu tháº­p tiÃªu Ä‘á» Äiá»u nhiá»u dÃ²ng (chá»¯ in Ä‘áº­m)\n",
    "        if is_collecting_dieu_title:\n",
    "            dieu_title_buffer.append(line_stripped)\n",
    "            continue\n",
    "        \n",
    "        # Thu tháº­p ná»™i dung Äiá»ƒm nhiá»u dÃ²ng\n",
    "        if is_collecting_diem_content:\n",
    "            diem_content_buffer.append(line_stripped)\n",
    "            continue\n",
    "        \n",
    "        # Thu tháº­p ná»™i dung Khoáº£n nhiá»u dÃ²ng\n",
    "        if is_collecting_khoan_content:\n",
    "            khoan_content_buffer.append(line_stripped)\n",
    "            continue\n",
    "        \n",
    "        # Ná»™i dung tiáº¿p theo\n",
    "        buffer.append(line_stripped)\n",
    "    \n",
    "    # LÆ°u buffer cuá»‘i\n",
    "    if is_collecting_dieu_title and current_dieu:\n",
    "        current_dieu[\"tieu_de\"] = ' '.join(dieu_title_buffer).strip()\n",
    "    elif is_collecting_diem_content and current_diem:\n",
    "        current_diem[\"noi_dung\"] = ' '.join(diem_content_buffer).strip()\n",
    "    elif is_collecting_khoan_content and current_khoan:\n",
    "        current_khoan[\"noi_dung\"] = ' '.join(khoan_content_buffer).strip()\n",
    "    elif current_diem and buffer:\n",
    "        current_diem[\"noi_dung\"] += ' ' + ' '.join(buffer).strip()\n",
    "    elif current_khoan and buffer:\n",
    "        current_khoan[\"noi_dung\"] += ' ' + ' '.join(buffer).strip()\n",
    "    \n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3a04b",
   "metadata": {},
   "source": [
    "## ðŸš€ Sá»¬ Dá»¤NG PHIÃŠN Báº¢N Má»šI\n",
    "\n",
    "Cháº¡y cell bÃªn dÆ°á»›i Ä‘á»ƒ xá»­ lÃ½ PDF vá»›i cáº¥u trÃºc JSON Ä‘áº§y Ä‘á»§ hÆ¡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbb3b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Há»† THá»NG TRÃCH XUáº¤T VÄ‚N Báº¢N PHÃP LUáº¬T - PHIÃŠN Báº¢N 2\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ BÆ¯á»šC 1: PhÃ¢n tÃ­ch loáº¡i PDF...\n",
      "   Káº¿t quáº£: âœ“ PDF Scan (cáº§n OCR)\n",
      "\n",
      "ðŸ“„ BÆ¯á»šC 2: TrÃ­ch xuáº¥t ná»™i dung...\n",
      "   âœ“ ÄÃ£ chuyá»ƒn 108 trang sang áº£nh\n",
      "   ðŸ”„ Äang xá»­ lÃ½: 108/108 trang...\n",
      "   âœ“ HoÃ n thÃ nh OCR: 108 trang\n",
      "   âœ“ TrÃ­ch xuáº¥t: 187,486 kÃ½ tá»±\n",
      "\n",
      "ðŸ”§ BÆ¯á»šC 3: Chuáº©n hÃ³a vÄƒn báº£n...\n",
      "   âœ“ Sau chuáº©n hÃ³a: 185,988 kÃ½ tá»±\n",
      "\n",
      "âš™ï¸  BÆ¯á»šC 4: PhÃ¢n tÃ­ch cáº¥u trÃºc...\n",
      "   âœ“ Sá»‘ hiá»‡u: 144/2025/NÄ-CP\n",
      "   âœ“ Loáº¡i vÄƒn báº£n: Luáº­t\n",
      "   âœ“ Sá»‘ ChÆ°Æ¡ng: 2\n",
      "   âœ“ Tá»•ng sá»‘ Äiá»u: 58\n",
      "\n",
      "ðŸ’¾ BÆ¯á»šC 5: LÆ°u file JSON...\n",
      "   âœ“ File JSON: D:/NCKH/DataPhuc/pdf_to_json/144-ndcp.signed_bá»™ xÃ¢y dá»±ng_v2.json\n",
      "   âœ“ KÃ­ch thÆ°á»›c: 255,331 kÃ½ tá»±\n",
      "\n",
      "======================================================================\n",
      "âœ… HOÃ€N THÃ€NH!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š PREVIEW Káº¾T QUáº¢ (metadata + cáº¥u trÃºc Ä‘áº§u tiÃªn):\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"loai_van_ban\": \"Luáº­t\",\n",
      "    \"so_hieu\": \"144/2025/NÄ-CP\",\n",
      "    \"trich_yeu\": \"\",\n",
      "    \"co_quan_ban_hanh\": \"sáº£n tá»™c TIM ÄIá»†N Tá»ª CHÃNH PHá»¦ NGHá»Š Äá»ŠNH\",\n",
      "    \"nguoi_ky\": \"\",\n",
      "    \"ngay_ban_hanh\": \"19/02/2025\",\n",
      "    \"ngay_hieu_luc\": \"\",\n",
      "    \"so_trang\": 0\n",
      "  },\n",
      "  \"phan_mo_dau\": {\n",
      "    \"co_quan_ban_hanh\": \"sáº£n tá»™c TIM ÄIá»†N Tá»ª CHÃNH PHá»¦ NGHá»Š Äá»ŠNH\",\n",
      "    \"ten_quoc_gia\": \"\",\n",
      "    \"quoc_hieu\": \"\",\n",
      "    \"so_hieu\": \"144/2025/NÄ-CP\",\n",
      "    \"noi_ban_hanh\": \"\",\n",
      "    \"ngay_thang_nam\": \"CÄƒn cá»± Nghá»‹ quyáº¿t sá»‘ 190/2025/QH15 ngÃ y 19 thÃ¡ng 02 nÄƒm 2025 cá»§a\"\n",
      "  },\n",
      "  \"ten_van_ban\": \"\",\n",
      "  \"can_cu_phap_ly\": [\n",
      "    \"CÄƒn cá»© Luáº­t Tá»• chá»©c ChÃ­nh phá»§ nÄƒm 2025; CÄƒn cá»© Luáº­t Tá»• chá»©c chÃ­nh quyá»n Ä‘á»‹a phÆ°Æ¡ng nÄƒm 2025, CÄƒn cá»± Nghá»‹ quyáº¿t sá»‘ 190/2025/QH15 ngÃ y 19 thÃ¡ng 02 nÄƒm 2025 cá»§a Quá»‘c há»™i quy Ä‘á»‹nh vá» xá»­ lÃ½ má»™t sá»‘ váº¥n Ä‘á» liÃªn quan Ä‘áº¿n sáº¯p xáº¿p tá»• chá»©c bá»™ mÃ¡y nhÃ  nÆ°á»›c, Theo Ä‘á» nghá»‹ cá»§a Bá»™ trÆ°á»Ÿng Bá»™ XÃ¢y dá»±ng, ` ChÃ­nh phá»§ ban hÃ nh Nghá»‹ Ä‘á»‹nh quy Ä‘á»‹nh vá» phÃ¢n quyÃªn, phÃ¢n cáº¥p trong HÃ¬nh vá»±c quáº£n lÃ½ nhÃ  nÆ°á»›c cá»§a Bá»™ XÃ¢y dá»±ng. ChÆ°Æ¡ng I QUY Äá»ŠNH CHUNG Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh Nghá»‹ Ä‘á»‹nh nÃ y quy Ä‘á»‹nh thÃ¢m quyÃªn, trÃ¬nh tá»±, thá»§ tá»¥c thá»±c hiá»‡n nhiá»‡m vá»¥, quyá»n háº¡n cá»§a cÆ¡ quan, ngÆ°á»i cÃ³ tháº©m quyá»ƒn trong lÄ©nh vá»±c quáº£n lÃ½ nhÃ  nÆ°á»›c cá»§a Bá»™ XÃ¢y dá»±ng Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i luáº­t, nghá»‹ quyáº¿t cá»§a Quá»‘c há»™i, phÃ¡p lá»‡nh, nghá»‹ quyáº¿t cá»§a á»¦y ban ThÆ°á»ng vá»¥ Quá»‘c há»™i, nghá»‹ Ä‘á»‹nh cá»§a ChÃ­nh phá»§, quyáº¿t Ä‘á»‹nh cá»§a Thá»§ tÆ°á»›ng ChÃ­nh phá»§ cáº§n Ä‘iá»u chá»‰nh Ä‘á»ƒ thá»±c hiá»‡n phÃ¢n quyá»n, phÃ¢n cáº¥p. ÄiÃªu 2. NguyÃªn táº¯c phÃ¢n cáº¥p, phÃ¢n quyá»n 1. NguyÃªn táº¯c chung a) Báº£o Ä‘áº£m phÃ¹ há»£p Vá»šI quy Ä‘á»‹nh cá»§a Hiáº¿n phÃ¡p; phÃ¹ há»£p vá»›i cÃ¡c nguyÃªn táº¯c, quy Ä‘á»‹nh vÃª phÃ¢n quyá»n, phÃ¢n cáº¥p cá»§a Luáº­t Tá»• chá»©c ChÃ­nh phá»§, Luáº­t Tá»• chá»©c chÃ­nh quyá»n Ä‘á»‹a phÆ°Æ¡ng;\",\n",
      "    \"CÄƒn cá»© Luáº­t NhÃ  á»Ÿ sá»‘ 27/2023/QH15 ngÃ y 27 thÃ¡ng 11 nÄƒm 2023; CÄƒn cá»© Nghá»‹ Ä‘á»‹nh sá»‘...../2024/NÄ-CP ngÃ y....thÃ¡ng....nÄƒm 2024 cá»§a ChÃ­nh phá»§ quy Ä‘á»‹nh chá»‰ tiáº¿t má»™t sÃ´ Ä‘iÃªu cá»§a Luáº­t NhÃ  á»Ÿ;\",\n",
      "    \"CÄƒn cá»© cÃ¡c quy Ä‘á»‹nh hiá»‡n hÃ nh vá» tá»• chá»©c, quáº£n lÃ½ hoáº¡t Ä‘á»™ng váº­n táº£i hÃ nh khÃ¡ch cÃ³ Ä‘á»‹nh giá»¯a Viá»‡t Nam vÃ  LÃ o;\",\n",
      "    \"CÄƒn cá»© cÃ¡c quy Ä‘á»‹nh hiá»‡n hÃ nh vá» tá»• chá»©c, quáº£n lÃ½ hoáº¡t Ä‘á»™ng váº­n táº£i hÃ nh khÃ¡ch cá»‘ Ä‘á»‹nh bÄƒng Ã´ tÃ´ giá»¯a Viá»‡t Nam vÃ  LÃ o;\",\n",
      "    \"CÄƒn cá»© cÃ¡c quy Ä‘á»‹nh hiá»‡n hÃ nh vá» tá»• chá»©c, quáº£n lÃ½ hoáº¡t Ä‘á»™ng váº­n táº£i hÃ nh khÃ¡ch cÃ´ Ä‘á»‹nh giá»¯a Viá»‡t Nam vÃ  Campuchia;\",\n",
      "    \"CÄƒn cá»© cÃ¡c quy Ä‘á»‹nh hiá»‡n hÃ nh vá» tÃ´ chá»©c, quáº£n lÃ½ hoáº¡t Ä‘á»™ng váº­n táº£i hÃ nh khÃ¡ch cá»‘ Ä‘á»‹nh giá»¯a Viá»‡t Nam vÃ  Campuchia;\",\n",
      "    \"CÄƒn cá»© Nghá»‹ Ä‘á»‹nh sá»‘ ... CÄƒn cá»© cÃ´ng vÄƒn sá»‘ . \\\" 5. .mmMm. Cho phÃ©p: .............. - (ghi tÃªn, sá»‘ áº¿ Giáº¥y chá»©ng nháº­n Ä‘Äƒng kÃ½ doanh nghiá»‡p (hoáº·c Giáº¥y chá»©ng nháº­n Ä‘áº§u 4u), ngÃ y cáº¥p, cÆ¡ quan cáº¥p; Ä‘á»‹a chá»‰, Ä‘iá»‡n thoáº¡i cá»§a. tá»• chá»©c, cÃ¡ nhÃ¢n Ä‘á» nghá»‹ nháº­p kháº©u) nháº­p kháº©u phÃ¡o hiá»‡u hÃ ng háº£i vá»›i chá»§ng loáº¡i, sá»‘ lÆ°á»£ng nhÆ° sau: (Ghi rÃµ chá»§ng loáº¡i, sá»‘ lÆ°á»£ng, kÃ½ mÃ£ hiá»‡u, nÆ°á»›c sáº£n xuáº¥t cá»§a tá»«ng loáº¡i phÃ¡o hiá»‡u). Tá»• chá»©c cÃ¡ nhÃ¢n Ä‘Æ°á»£c phÃ©p nháº­p khÃ¢u phÃ¡o hiá»‡u hÃ ng háº£i cÃ³ trÃ¡ch nhiá»‡m thá»±c hiá»‡n cÃ¡c quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» nháº­p khÃ¢u hÃ ng hÃ³a, cháº¥t lÆ°á»£ng hÃ ng hÃ³a vÃ  sá»­ dá»¥ng Ä‘Ãºng má»¥c Ä‘Ã­ch cho phÃ©p. Giáº¥y phÃ©p cÃ³ giÃ¡ trá»‹ Ä‘áº¿n ngÃ y........ thÃ¡ng ........ nÄƒm ....... \\\"n nhá»‡n: Ã¡\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# WORKFLOW V2: Xá»­ lÃ½ vá»›i cáº¥u trÃºc JSON Ä‘áº§y Ä‘á»§\n",
    "import os\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Há»† THá»NG TRÃCH XUáº¤T VÄ‚N Báº¢N PHÃP LUáº¬T - PHIÃŠN Báº¢N 2\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "\n",
    "# BÆ°á»›c 1: PhÃ¢n loáº¡i PDF\n",
    "print(\"ðŸ“‹ BÆ¯á»šC 1: PhÃ¢n tÃ­ch loáº¡i PDF...\")\n",
    "is_text = is_text_pdf(pdf_path)\n",
    "print(f\"   Káº¿t quáº£: {'âœ“ PDF Text (trÃ­ch xuáº¥t trá»±c tiáº¿p)' if is_text else 'âœ“ PDF Scan (cáº§n OCR)'}\")\n",
    "print()\n",
    "\n",
    "# BÆ°á»›c 2: TrÃ­ch xuáº¥t vÄƒn báº£n\n",
    "print(\"ðŸ“„ BÆ¯á»šC 2: TrÃ­ch xuáº¥t ná»™i dung...\")\n",
    "if is_text:\n",
    "    raw_text = extract_text_pdf(pdf_path)\n",
    "else:\n",
    "    images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "    print(f\"   âœ“ ÄÃ£ chuyá»ƒn {len(images)} trang sang áº£nh\")\n",
    "    raw_text = ocr_from_pdf_images(images)\n",
    "\n",
    "print(f\"   âœ“ TrÃ­ch xuáº¥t: {len(raw_text):,} kÃ½ tá»±\")\n",
    "print()\n",
    "\n",
    "# BÆ°á»›c 3: Chuáº©n hÃ³a\n",
    "print(\"ðŸ”§ BÆ¯á»šC 3: Chuáº©n hÃ³a vÄƒn báº£n...\")\n",
    "raw_text = normalize_text(raw_text)\n",
    "print(f\"   âœ“ Sau chuáº©n hÃ³a: {len(raw_text):,} kÃ½ tá»±\")\n",
    "print()\n",
    "\n",
    "# BÆ°á»›c 4: Parse vá»›i cáº¥u trÃºc má»›i\n",
    "print(\"âš™ï¸  BÆ¯á»šC 4: PhÃ¢n tÃ­ch cáº¥u trÃºc...\")\n",
    "parsed_v2 = parse_legal_document_v2(raw_text)\n",
    "print(f\"   âœ“ Sá»‘ hiá»‡u: {parsed_v2['metadata']['so_hieu'] or 'ChÆ°a xÃ¡c Ä‘á»‹nh'}\")\n",
    "print(f\"   âœ“ Loáº¡i vÄƒn báº£n: {parsed_v2['metadata']['loai_van_ban'] or 'ChÆ°a xÃ¡c Ä‘á»‹nh'}\")\n",
    "print(f\"   âœ“ Sá»‘ ChÆ°Æ¡ng: {len(parsed_v2['chuong'])}\")\n",
    "\n",
    "total_dieu = sum(len(ch['dieu']) for ch in parsed_v2['chuong'])\n",
    "print(f\"   âœ“ Tá»•ng sá»‘ Äiá»u: {total_dieu}\")\n",
    "print()\n",
    "\n",
    "# BÆ°á»›c 5: Xuáº¥t JSON\n",
    "print(\"ðŸ’¾ BÆ¯á»šC 5: LÆ°u file JSON...\")\n",
    "json_v2 = json.dumps(parsed_v2, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Cho phÃ©p chá»n nÆ¡i lÆ°u file\n",
    "default_filename = os.path.splitext(os.path.basename(pdf_path))[0] + \"_v2.json\"\n",
    "output_v2 = filedialog.asksaveasfilename(\n",
    "    defaultextension=\".json\",\n",
    "    filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")],\n",
    "    initialfile=default_filename,\n",
    "    title=\"Chá»n nÆ¡i lÆ°u file JSON\"\n",
    ")\n",
    "\n",
    "if not output_v2:\n",
    "    print(\"   âš ï¸ KhÃ´ng chá»n file, há»§y lÆ°u.\")\n",
    "else:\n",
    "    with open(output_v2, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_v2)\n",
    "\n",
    "    print(f\"   âœ“ File JSON: {output_v2}\")\n",
    "    print(f\"   âœ“ KÃ­ch thÆ°á»›c: {len(json_v2):,} kÃ½ tá»±\")\n",
    "    print()\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"âœ… HOÃ€N THÃ€NH!\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "\n",
    "    # Preview\n",
    "    print(\"ðŸ“Š PREVIEW Káº¾T QUáº¢ (metadata + cáº¥u trÃºc Ä‘áº§u tiÃªn):\")\n",
    "    print(\"-\"*70)\n",
    "    print(json_v2[:3000] + \"\\n...\" if len(json_v2) > 3000 else json_v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
